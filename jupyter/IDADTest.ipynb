{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/fcdl/Develop/ICL/\")\n",
    "from data.idadataloader import IDADataloader \n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data.common import DatasetPrototypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "augmentation = transforms.Compose([transforms.Resize(400), transforms.RandomCrop(224)])\n",
    "\n",
    "targ = ImageFolder('/home/fcdl/dataset/office/Art')\n",
    "src = ImageFolder('/home/fcdl/dataset/office/Product')\n",
    "data = IDADataloader(targ, src, \n",
    "                  num_cl_first=10, num_cl_after=5, \n",
    "                  augmentation=augmentation, transform=transform, \n",
    "                  batch_size=64, run_number=0, workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example image from target\n",
    "data.target[0][0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example image from source\n",
    "data.source[0][0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Same order!\n"
     ]
    }
   ],
   "source": [
    "# Check if get dataloader returns the same images and in the same order as get images\n",
    "# And, moreover, that images are returned as tensor not normalized or augmented\n",
    "# That dataloader and prototypes are normalized in the same way\n",
    "\n",
    "proto_x = []\n",
    "proto_y = []\n",
    "\n",
    "idx = [3]\n",
    "\n",
    "for i in idx:\n",
    "    img = data.get_images_of_class(i)\n",
    "    proto_x += img\n",
    "    proto_y += [i for j in range(len(img))]\n",
    "    \n",
    "\n",
    "proto_set = DatasetPrototypes(proto_x, proto_y, transform) # same as applying the target transform to proto\n",
    "\n",
    "dl = data.get_dataloader_of_class(3)\n",
    "# reconstruct the list of images from dataloader\n",
    "ll = []\n",
    "for img, tar in dl:\n",
    "    ll.append(img)\n",
    "\n",
    "images = torch.cat(ll)\n",
    "\n",
    "flag = True\n",
    "for i in range(len(proto_set)):\n",
    "    if not torch.all(torch.eq(images[i], proto_set[i][0])):\n",
    "        flag = False\n",
    "\n",
    "print(len(proto_set))\n",
    "if flag:\n",
    "    print(\"Same order!\")\n",
    "else:\n",
    "    assert False, \"Not same order\"\n",
    "\n",
    "#proto_x[0].show()\n",
    "#print(proto_set[0][0])\n",
    "#print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
