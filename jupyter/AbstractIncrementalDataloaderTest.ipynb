{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/fcdl/Develop/ICL/\")\n",
    "from data.iCIFAR import ICIFAR\n",
    "from data.idadataloader import IDADataloader \n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data.common import DatasetPrototypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose the dataset to test!\n",
    "dataset = 'cifar'\n",
    "# dataset = 'idad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_protos(idx):\n",
    "    proto_x = []\n",
    "    proto_y = []\n",
    "\n",
    "    for i in idx:\n",
    "        img = data.get_images_of_class(i)\n",
    "        proto_x += img\n",
    "        proto_y += [i for j in range(len(img))]\n",
    "    \n",
    "    return proto_x, proto_y\n",
    "\n",
    "num_cl_first = 5\n",
    "num_cl_after = num_cl_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'cifar':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(ICIFAR.MEAN, ICIFAR.STD)])\n",
    "\n",
    "    augmentation = transforms.RandomCrop((32,32), padding=4)\n",
    "\n",
    "    data = ICIFAR('/home/fcdl/dataset', download=False, num_cl_first=num_cl_first, num_cl_after=num_cl_after, \n",
    "                  augmentation=None, transform=transform, batch_size=64, run_number=0, workers=8)\n",
    "    # Show example image\n",
    "    data.train_dataset[0][0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([transforms.ToPILImage(),augmentation])\n",
    "\n",
    "tr(data.valid_dataset[0][0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'idad':\n",
    "    transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "    augmentation = transforms.Compose([transforms.Resize(400), transforms.RandomCrop(224)])\n",
    "\n",
    "    targ = ImageFolder('/home/fcdl/dataset/office/Art')\n",
    "    src = ImageFolder('/home/fcdl/dataset/office/Product')\n",
    "    data = IDADataloader(targ, src, \n",
    "                      num_cl_first=num_cl_first, num_cl_after=num_cl_after, \n",
    "                      augmentation=augmentation, transform=transform, \n",
    "                      batch_size=64, run_number=0, workers=8)\n",
    "    # Show example image from target\n",
    "    data.target[0][0].show()\n",
    "    # Show example image from source\n",
    "    data.source[0][0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "Same order!\n"
     ]
    }
   ],
   "source": [
    "# Check if get dataloader returns the same images and in the same order as get images\n",
    "# And, moreover, that images are returned as tensor not normalized or augmented\n",
    "# That dataloader and prototypes are normalized in the same way\n",
    "\n",
    "proto_set = DatasetPrototypes(*make_protos([19]), transform) # same as applying the target transform to proto\n",
    "\n",
    "dl = data.get_dataloader_of_class(19)\n",
    "# reconstruct the list of images from dataloader\n",
    "ll = []\n",
    "for img, tar in dl:\n",
    "    ll.append(img)\n",
    "\n",
    "images = torch.cat(ll)\n",
    "\n",
    "flag = True\n",
    "for i in range(len(proto_set)):\n",
    "    if not torch.all(torch.eq(images[i], proto_set[i][0])):\n",
    "        flag = False\n",
    "        \n",
    "print(len(proto_set))\n",
    "if flag:\n",
    "    print(\"Same order!\")\n",
    "else:\n",
    "    assert False, \"Not same order\"\n",
    "\n",
    "#proto_x[0].show()\n",
    "#print(proto_set[0][0])\n",
    "#print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class should be\n",
      "[0, 1, 2, 3, 4]\n",
      "Classes are\n",
      "[0, 1, 2, 3, 4]\n",
      "257\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# check if dataloader of training works\n",
    "first = True\n",
    "#first = False\n",
    "\n",
    "if first:\n",
    "    data.reset_iteration()\n",
    "    iteration = 0\n",
    "else:\n",
    "    iteration += 1\n",
    "    \n",
    "order = [x.item() for x in data.order[data.offset(iteration-1): data.offset(iteration)]]\n",
    "print(f\"Class should be\\n{sorted(order)}\")\n",
    "\n",
    "data_loader = data.next_iteration()\n",
    "\n",
    "print(f\"Classes are\")\n",
    "count = 0\n",
    "first = True\n",
    "for inp, target in data_loader:\n",
    "    count += inp.shape[0]\n",
    "    if first:\n",
    "        print([x.item() for x in target.unique().sort()[0]])\n",
    "        first = False     \n",
    "\n",
    "# for easiness of testing, set num_cl_first = num_cl_after\n",
    "print(count)\n",
    "if dataset == 'cifar':\n",
    "    assert count == 500  * num_cl_first, \"Not all samples are returned\"\n",
    "elif dataset == 'idad':\n",
    "    assert num_cl_first*50 < count < num_cl_first*60, \"Not all samples are returned\"\n",
    "\n",
    "print(\"\\nOK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class should be\n",
      "[0, 1, 2, 3, 4, 27, 29]\n",
      "Classes are\n",
      "[0, 1, 2, 3, 4, 27, 29]\n",
      "446\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# check if dataloader of training works\n",
    "first = True\n",
    "idx = [27, 29]\n",
    "\n",
    "if first:\n",
    "    data.reset_iteration()\n",
    "    iteration = 0\n",
    "else:\n",
    "    iteration += 1\n",
    "    \n",
    "order = [x.item() for x in data.order[data.offset(iteration-1): data.offset(iteration)]]\n",
    "print(f\"Class should be\\n{sorted(order + idx)}\")\n",
    "\n",
    "proto_len = len(make_protos(idx)[0])\n",
    "data_loader = data.next_iteration(*make_protos(idx))\n",
    "\n",
    "print(f\"Classes are\")\n",
    "count = 0\n",
    "first = True\n",
    "for inp, target in data_loader:\n",
    "    count += inp.shape[0]\n",
    "    if first:\n",
    "        print([x.item() for x in target.unique().sort()[0]])\n",
    "        first = False\n",
    "\n",
    "# for easiness of testing, set num_cl_first = num_cl_after \n",
    "n_c = num_cl_first+len(idx)\n",
    "print(count)\n",
    "if dataset == 'cifar':\n",
    "    assert count == 500  * (n_c), \"Not all samples are returned\"\n",
    "elif dataset == 'idad':\n",
    "    assert num_cl_first*50 < count - proto_len < num_cl_first*60, \"Not all samples are returned\"\n",
    "    assert proto_len == 189, \"Please, set proto idx to 27, 29\"\n",
    "\n",
    "print(\"\\nOK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class should be\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "They are\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "1089\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# check if dataloader of validation works\n",
    "#first = True\n",
    "first = False\n",
    "\n",
    "if first:\n",
    "    data.reset_iteration()\n",
    "    iteration = 0\n",
    "else:\n",
    "    iteration += 1\n",
    "    \n",
    "order = [x.item() for x in data.order[0: data.offset(iteration)]]\n",
    "print(f\"Class should be\\n{sorted(order)}\")\n",
    "\n",
    "dl = data.test_dataloader(iteration=iteration)\n",
    "\n",
    "count = 0\n",
    "classes = []\n",
    "for inp, target in dl:\n",
    "    count += inp.shape[0]\n",
    "    classes += [x.item() for x in target.unique().sort()[0]]\n",
    "\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(f\"They are\\n{classes}\")\n",
    "\n",
    "# for easiness of testing, set num_cl_first = num_cl_after \n",
    "n_c = num_cl_first*(iteration+1)\n",
    "print(count)\n",
    "if dataset == 'cifar':\n",
    "    assert count == 100  * (n_c), \"Not all samples are returned\"\n",
    "elif dataset == 'idad':\n",
    "    assert n_c*40 < count < n_c*60, \"Not all samples are returned\"\n",
    "\n",
    "print(\"\\nOK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
